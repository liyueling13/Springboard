{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone 2 on RDU Airline Delays - Modeling2\n",
    "10/19/22\n",
    "\n",
    "We have wrangled, explored, and preprocessed our data. Now let's create some models to predict whether or not a flight will be delayed/cancelled. (This is attempt 2 because I realized an issue with my dataset.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "\n",
    "X_train = pd.read_csv('X_train2.csv')\n",
    "X_test = pd.read_csv('X_test2.csv')\n",
    "y_train = pd.read_csv('y_train2.csv')\n",
    "y_test = pd.read_csv('y_test2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "X_test.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "y_train.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "y_test.drop(['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FL_NUM', 'QUARTER_2', 'QUARTER_3', 'QUARTER_4', 'MONTH_2', 'MONTH_3',\n",
       "       'MONTH_4', 'MONTH_5', 'MONTH_6', 'MONTH_7',\n",
       "       ...\n",
       "       'DEST_TTN', 'DEST_VPS', 'DEP_TIME_BINS_LATE_NIGHT',\n",
       "       'DEP_TIME_BINS_MIDDAY', 'DEP_TIME_BINS_MORNING',\n",
       "       'ARR_TIME_BINS_LATE_NIGHT', 'ARR_TIME_BINS_MIDDAY',\n",
       "       'ARR_TIME_BINS_MORNING', 'CRS_ELAPSED_TIME_LG', 'DISTANCE_LG'],\n",
       "      dtype='object', length=124)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.DataFrame(y_train).to_numpy().ravel()\n",
    "y_test = pd.DataFrame(y_test).to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's hard to remember now what my columns are, so here's the list of columns before get_dummies:\n",
    "\n",
    "         QUARTER              52645 non-null  category\n",
    "         MONTH                52645 non-null  category\n",
    "         DAY_OF_MONTH         52645 non-null  category\n",
    "         DAY_OF_WEEK          52645 non-null  category\n",
    "         CARRIER              52645 non-null  object  \n",
    "         FL_NUM               52645 non-null  object  \n",
    "         DEST                 52645 non-null  object  \n",
    "         CRS_ELAPSED_TIME_LG  52645 non-null  float64 \n",
    "         DISTANCE_LG          52645 non-null  float64\n",
    "         DEP_TIME_BINS        52645 non-null  object  \n",
    "         ARR_TIME_BINS        52626 non-null  object  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is what our RESULT column corresponds to:\n",
    "\n",
    "                0 = no delay\n",
    "                1 = delay of 1 hour or less\n",
    "                2 = delay of 2 hours or less\n",
    "                3 = delay of more than 2 hours\n",
    "                4 = cancelled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "Since we're trying to solve a multiclass classification problem, we can use the following models:\n",
    "\n",
    "        0. Dummy Classifier\n",
    "        1. KNN Classifier\n",
    "        2. Logistic Regression\n",
    "        3. Random Forest Classifier\n",
    "        4. Gradient Boosting Classifier\n",
    "        \n",
    "We've already done our preprocessing/scaling and standardizing. The remaining columns that we haven't scaled are objects or binary categories. We'll perform cross validation with KFold, hyperparameter tuning with RandomizedSearchCV, and put these together with a pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Dummy Classifier\n",
    "\n",
    "The sklearn dummy classifier will give us a baseline with which to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score on Training Set for Dummy Classifier: 0.50016\n",
      "Accuracy Score on Test Set for Dummy Classifier: 0.49952\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy Score on Training Set for Dummy Classifier: {}\".format(dummy_clf.score(X_train, y_train)))\n",
    "print(\"Accuracy Score on Test Set for Dummy Classifier: {}\".format(dummy_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dummy = dummy_clf.predict(X_test)\n",
    "y_probs_dummy = dummy_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score on Test Set for Dummy Classifier: 0.49952\n",
      "Precision Score - weighted averaged on Test Set for Dummy Classifier: 0.2495202304\n",
      "Recall Score - weighted averaged on Test Set for Dummy Classifier: 0.49952\n",
      "F1 Score - weighted averaged on Test Set for Dummy Classifier: 0.332800136577038\n",
      "ROC-AUC score - weighted averaged on Test Set for Dummy Classifier: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "print(\"Accuracy Score on Test Set for Dummy Classifier: {}\"\n",
    "      .format(accuracy_score(y_test, y_pred_dummy)))\n",
    "print(\"Precision Score - weighted averaged on Test Set for Dummy Classifier: {}\"\n",
    "      .format(precision_score(y_test, y_pred_dummy, average='weighted')))\n",
    "print(\"Recall Score - weighted averaged on Test Set for Dummy Classifier: {}\"\n",
    "      .format(recall_score(y_test, y_pred_dummy, average='weighted')))\n",
    "print(\"F1 Score - weighted averaged on Test Set for Dummy Classifier: {}\"\n",
    "      .format(f1_score(y_test, y_pred_dummy, average='weighted')))\n",
    "print(\"ROC-AUC score - weighted averaged on Test Set for Dummy Classifier: {}\"\n",
    "      .format(roc_auc_score(y_test, y_probs_dummy, average='weighted', multi_class='ovo')))\n",
    "\n",
    "# # note: since my dataset is still slightly imbalanced, I'm using average=weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have pretty mediocre numbers for this dummy classifier, so looks like our models won't have to work too hard to beat these metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "                   param_distributions={'n_neighbors': array([ 1,  3,  5,  7,  9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33,\n",
       "       35, 37, 39, 41, 43, 45, 47, 49]),\n",
       "                                        'p': [1, 2],\n",
       "                                        'weights': ['uniform', 'distance']})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "params = {\"n_neighbors\": np.arange(1, 50, 2),\n",
    "        \"weights\": ['uniform', 'distance'],\n",
    "         'p': [1, 2]}\n",
    "knn_cv = RandomizedSearchCV(knn, params, cv=5)\n",
    "knn_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned KNN Classifier Parameters: {'weights': 'distance', 'p': 1, 'n_neighbors': 43}\n",
      "Tuned KNN Classifier Best Accuracy Score: 0.8306666666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"Tuned KNN Classifier Parameters: {}\".format(knn_cv.best_params_))\n",
    "print(\"Tuned KNN Classifier Best Accuracy Score: {}\".format(knn_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate some metrics for this KNN classifier: accuracy, precision, and ROC-AUC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_knn = knn_cv.predict(X_test)\n",
    "y_probs_knn = knn_cv.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score on Test Set for KNN Classifier: 0.85256\n",
      "Precision Score - weighted averaged on Test Set for KNN Classifier: 0.8604214834908291\n",
      "Recall Score - weighted averaged on Test Set for KNN Classifier: 0.85256\n",
      "F1 Score - weighted averaged on Test Set for KNN Classifier: 0.8538858273467026\n",
      "ROC-AUC score - weighted averaged on Test Set for KNN Classifier: 0.95906915448453\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score on Test Set for KNN Classifier: {}\"\n",
    "      .format(accuracy_score(y_test, y_pred_knn)))\n",
    "print(\"Precision Score - weighted averaged on Test Set for KNN Classifier: {}\"\n",
    "      .format(precision_score(y_test, y_pred_knn, average='weighted')))\n",
    "print(\"Recall Score - weighted averaged on Test Set for KNN Classifier: {}\"\n",
    "      .format(recall_score(y_test, y_pred_knn, average='weighted')))\n",
    "print(\"F1 Score - weighted averaged on Test Set for KNN Classifier: {}\"\n",
    "      .format(f1_score(y_test, y_pred_knn, average='weighted')))\n",
    "print(\"ROC-AUC score - weighted averaged on Test Set for KNN Classifier: {}\"\n",
    "      .format(roc_auc_score(y_test, y_probs_knn, average='weighted', multi_class='ovo')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:278: UserWarning: The total space of parameters 5 is smaller than n_iter=10. Running 5 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "                   param_distributions={'C': [100, 10, 1.0, 0.1, 0.01]})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# took forever to run a RandomizedSearchCV with more parameters,\n",
    "# so stripped it down to just one parameter for a \"baseline metric\"\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression()\n",
    "params = {\"C\": [100, 10, 1.0, 0.1, 0.01]}\n",
    "LR_cv = RandomizedSearchCV(LR, params, cv=5)\n",
    "LR_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameters: {'C': 0.01}\n",
      "Tuned Logistic Regression Best Accuracy Score: 0.5238400000000001\n"
     ]
    }
   ],
   "source": [
    "print(\"Tuned Logistic Regression Parameters: {}\"\n",
    "      .format(LR_cv.best_params_))\n",
    "print(\"Tuned Logistic Regression Best Accuracy Score: {}\"\n",
    "      .format(LR_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_LR = LR_cv.predict(X_test)\n",
    "y_probs_LR = LR_cv.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score on Test Set for Logistic Regression Classifier: 0.52\n",
      "Precision Score - weighted averaged on Test Set for Logistic Regression Classifier: 0.39038691194207187\n",
      "Recall Score - weighted averaged on Test Set for Logistic Regression Classifier: 0.52\n",
      "F1 Score - weighted averaged on Test Set for Logistic Regression Classifier: 0.42608632238480376\n",
      "ROC-AUC score - weighted averaged on Test Set for Logistic Regression Classifier: 0.6175465272854115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score on Test Set for Logistic Regression Classifier: {}\"\n",
    "      .format(accuracy_score(y_test, y_pred_LR)))\n",
    "print(\"Precision Score - weighted averaged on Test Set for Logistic Regression Classifier: {}\"\n",
    "      .format(precision_score(y_test, y_pred_LR, average='weighted')))\n",
    "print(\"Recall Score - weighted averaged on Test Set for Logistic Regression Classifier: {}\"\n",
    "      .format(recall_score(y_test, y_pred_LR, average='weighted')))\n",
    "print(\"F1 Score - weighted averaged on Test Set for Logistic Regression Classifier: {}\"\n",
    "      .format(f1_score(y_test, y_pred_LR, average='weighted')))\n",
    "print(\"ROC-AUC score - weighted averaged on Test Set for Logistic Regression Classifier: {}\"\n",
    "      .format(roc_auc_score(y_test, y_probs_LR, average='weighted', multi_class='ovo')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have extremely poor numbers for logistic regression. The model would not converge! These \"baseline numbers\" however already demonstrate it would not be a good model for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "                   param_distributions={'criterion': ['gini', 'entropy'],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'n_estimators': array([ 25,  50,  75, 100, 125, 150, 175, 200, 225, 250, 275, 300, 325,\n",
       "       350, 375, 400, 425, 450, 475])})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF = RandomForestClassifier()\n",
    "params = {\"n_estimators\": np.arange(25, 500, 25),\n",
    "        \"criterion\": [\"gini\", \"entropy\"],\n",
    "          \"max_features\": ['auto', 'sqrt']}\n",
    "RF_cv = RandomizedSearchCV(RF, params, cv=5)\n",
    "RF_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Random Forest Classifier Parameters: {'n_estimators': 425, 'max_features': 'auto', 'criterion': 'gini'}\n",
      "Tuned Random Forest Classifier Best Accuracy Score: 0.8520800000000002\n"
     ]
    }
   ],
   "source": [
    "print(\"Tuned Random Forest Classifier Parameters: {}\".format(RF_cv.best_params_))\n",
    "print(\"Tuned Random Forest Classifier Best Accuracy Score: {}\".format(RF_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = RF_cv.predict(X_test)\n",
    "y_probs_rf = RF_cv.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score on Test Set for Random Forest Classifier: 0.88656\n",
      "Precision Score - weighted averaged on Test Set for Random Forest Classifier: 0.8878030167706007\n",
      "Recall Score - weighted averaged on Test Set for Random Forest Classifier: 0.88656\n",
      "F1 Score - weighted averaged on Test Set for Random Forest Classifier: 0.8867338091960775\n",
      "ROC-AUC score - weighted averaged on Test Set for Random Forest Classifier: 0.960010153347069\n"
     ]
    }
   ],
   "source": [
    "`print(\"Accuracy Score on Test Set for Random Forest Classifier: {}\"\n",
    "      .format(accuracy_score(y_test, y_pred_rf)))\n",
    "print(\"Precision Score - weighted averaged on Test Set for Random Forest Classifier: {}\"\n",
    "      .format(precision_score(y_test, y_pred_rf, average='weighted')))\n",
    "print(\"Recall Score - weighted averaged on Test Set for Random Forest Classifier: {}\"\n",
    "      .format(recall_score(y_test, y_pred_rf, average='weighted')))\n",
    "print(\"F1 Score - weighted averaged on Test Set for Random Forest Classifier: {}\"\n",
    "      .format(f1_score(y_test, y_pred_rf, average='weighted')))\n",
    "print(\"ROC-AUC score - weighted averaged on Test Set for Random Forest Classifier: {}\"\n",
    "      .format(roc_auc_score(y_test, y_probs_rf, average='weighted', multi_class='ovo')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model outperforms our (very good) KNN classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for some reason it was IMPOSSIBLE to run a RandomizedSearchCV on this classifier.\n",
    "# I let it run for hours and it never completed.\n",
    "# But let's try it with the default parameters to see if it's promising\n",
    "# (it's not)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "GBC = GradientBoostingClassifier()\n",
    "GBC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gbc = GBC.predict(X_test)\n",
    "y_probs_gbc = GBC.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score on Test Set for Gradient Boosting Classifier: 0.54856\n",
      "Precision Score - weighted averaged on Test Set for Gradient Boosting Classifier: 0.5627793693132978\n",
      "Recall Score - weighted averaged on Test Set for Gradient Boosting Classifier: 0.54856\n",
      "F1 Score - weighted averaged on Test Set for Gradient Boosting Classifier: 0.47528682737883166\n",
      "ROC-AUC score - weighted averaged on Test Set for Gradient Boosting Classifier: 0.715993475639177\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score on Test Set for Gradient Boosting Classifier: {}\"\n",
    "      .format(accuracy_score(y_test, y_pred_gbc)))\n",
    "print(\"Precision Score - weighted averaged on Test Set for Gradient Boosting Classifier: {}\"\n",
    "      .format(precision_score(y_test, y_pred_gbc, average='weighted')))\n",
    "print(\"Recall Score - weighted averaged on Test Set for Gradient Boosting Classifier: {}\"\n",
    "      .format(recall_score(y_test, y_pred_gbc, average='weighted')))\n",
    "print(\"F1 Score - weighted averaged on Test Set for Gradient Boosting Classifier: {}\"\n",
    "      .format(f1_score(y_test, y_pred_gbc, average='weighted')))\n",
    "print(\"ROC-AUC score - weighted averaged on Test Set for Gradient Boosting Classifier: {}\"\n",
    "      .format(roc_auc_score(y_test, y_probs_gbc, average='weighted', multi_class='ovo')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the RandomizedSearchCV never finished running on the GradientBoostingClassifier. Instead I set the normal parameters to get a baseline metric. As we can see, these weren't very good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The Random Forest Classifier outperforms the KNN Classifier, Logistic Regression, and Gradient Boosting Classifier. And of course it far outperforms the Dummy Classifier.\n",
    "\n",
    "For the RF Classifier we found optimal hyperparameters found through RandomizedSearchCV: {'n_estimators': 425, 'max_features': 'auto', 'criterion': 'gini'}.\n",
    "\n",
    "Our accuracy was 0.89,\n",
    "precision was 0.89,\n",
    "recall was 0.89,\n",
    "F1 score was 0.89,\n",
    "and ROC-AUC was 0.96."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving our best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "best_RF = RandomForestClassifier(n_estimators=425,\n",
    "                criterion='gini',\n",
    "                max_features='auto')\n",
    "best_model = best_RF.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import __version__ as sklearn_version\n",
    "import datetime\n",
    "import pickle\n",
    "best_model.version = 1.0\n",
    "best_model.pandas_version = pd.__version__\n",
    "best_model.numpy_version = np.__version__\n",
    "best_model.sklearn_version = sklearn_version\n",
    "best_model.X_columns = [col for col in X_train.columns]\n",
    "best_model.build_datetime = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "savedmodel = 'RDU_departure_predictions.pkl'\n",
    "pickle.dump(best_model, open(savedmodel, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
