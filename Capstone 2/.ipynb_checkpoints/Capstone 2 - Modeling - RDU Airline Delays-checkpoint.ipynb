{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone 2 on RDU Airline Delays - Modeling\n",
    "10/14/22\n",
    "\n",
    "We have wrangled, explored, and preprocessed our data. Now let's create some models to predict whether or not a flight will be delayed/cancelled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_validate, RandomizedSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "\n",
    "X_train = pd.read_csv('X_train.csv')\n",
    "X_test = pd.read_csv('X_test.csv')\n",
    "y_train = pd.read_csv('y_train.csv')\n",
    "y_test = pd.read_csv('y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "X_test.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "y_train.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "y_test.drop(['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.DataFrame(y_train).to_numpy().ravel()\n",
    "y_test = pd.DataFrame(y_test).to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's hard to remember now what my columns are, so here's the list of columns before get_dummies:\n",
    "\n",
    "         QUARTER              52645 non-null  category\n",
    "         MONTH                52645 non-null  category\n",
    "         DAY_OF_MONTH         52645 non-null  category\n",
    "         DAY_OF_WEEK          52645 non-null  category\n",
    "         CARRIER              52645 non-null  object  \n",
    "         FL_NUM               52645 non-null  object  \n",
    "         DEST                 52645 non-null  object  \n",
    "         CRS_ELAPSED_TIME_LG  52645 non-null  float64 \n",
    "         DISTANCE_LG          52645 non-null  float64 \n",
    "         CARRIER_DELAY        52645 non-null  category\n",
    "         WEATHER_DELAY        52645 non-null  category\n",
    "         NAS_DELAY            52645 non-null  category\n",
    "         SECURITY_DELAY       52645 non-null  category\n",
    "         LATE_AIRCRAFT_DELAY  52645 non-null  category\n",
    "         DEP_TIME_BINS        52645 non-null  object  \n",
    "         ARR_TIME_BINS        52626 non-null  object  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "Since we're trying to solve a multiclass classification problem, we can use the following models:\n",
    "\n",
    "        1. Random Forest\n",
    "        2. KNN\n",
    "        \n",
    "We've already done our preprocessing/scaling and standardizing. We'll perform cross validation with KFold, hyperparameter tuning with RandomizedSearchCV, and put these together with a pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "                   param_distributions={'criterion': ['gini', 'entropy'],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'n_estimators': array([ 25,  50,  75, 100, 125, 150, 175, 200, 225, 250, 275, 300, 325,\n",
       "       350, 375, 400, 425, 450, 475])})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF = RandomForestClassifier()\n",
    "params = {\"n_estimators\": np.arange(25, 500, 25),\n",
    "        \"criterion\": [\"gini\", \"entropy\"],\n",
    "          \"max_features\": ['auto', 'sqrt']}\n",
    "RF_cv = RandomizedSearchCV(RF, params, cv=5)\n",
    "RF_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Random Forest Classifier Parameters: {'n_estimators': 200, 'max_features': 'auto', 'criterion': 'gini'}\n",
      "Tuned Random Forest Classifier Best Accuracy Score: 0.849986028321324\n"
     ]
    }
   ],
   "source": [
    "print(\"Tuned Random Forest Classifier Parameters: {}\".format(RF_cv.best_params_))\n",
    "print(\"Tuned Random Forest Classifier Best Accuracy Score: {}\".format(RF_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate some metrics for this random forest classifier: accuracy, precision, and ROC-AUC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = RF_cv.predict(X_test)\n",
    "y_probs_rf = RF_cv.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score on Test Set for Random Forest Classifier: 0.8504786506609938\n",
      "Precision Score - weighted averaged on Test Set for Random Forest Classifier: 0.824977037253275\n",
      "ROC-AUC score - weighted averaged on Test Set for Random Forest Classifier: 0.8784947327590824\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score on Test Set for Random Forest Classifier: {}\".format(accuracy_score(y_test, y_pred_rf)))\n",
    "print(\"Precision Score - weighted averaged on Test Set for Random Forest Classifier: {}\".format(precision_score(y_test, y_pred_rf, average='weighted')))\n",
    "print(\"ROC-AUC score - weighted averaged on Test Set for Random Forest Classifier: {}\".format(roc_auc_score(y_test, y_probs_rf, average='weighted', multi_class='ovo')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "                   param_distributions={'n_neighbors': array([ 1,  3,  5,  7,  9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33,\n",
       "       35, 37, 39, 41, 43, 45, 47, 49]),\n",
       "                                        'p': [1, 2],\n",
       "                                        'weights': ['uniform', 'distance']})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "params = {\"n_neighbors\": np.arange(1, 50, 2),\n",
    "        \"weights\": ['uniform', 'distance'],\n",
    "         'p': [1, 2],}\n",
    "knn_cv = RandomizedSearchCV(knn, params, cv=5)\n",
    "knn_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned KNN Classifier Parameters: {'weights': 'distance', 'p': 1, 'n_neighbors': 15}\n",
      "Tuned KNN Classifier Best Accuracy Score: 0.8191626704971391\n"
     ]
    }
   ],
   "source": [
    "print(\"Tuned KNN Classifier Parameters: {}\".format(knn_cv.best_params_))\n",
    "print(\"Tuned KNN Classifier Best Accuracy Score: {}\".format(knn_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_knn = knn_cv.predict(X_test)\n",
    "y_probs_knn = knn_cv.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score on Test Set for KNN Classifier: 0.8130223370308464\n",
      "Precision Score - weighted averaged on Test Set for KNN Classifier: 0.7442509100408177\n",
      "ROC-AUC score - weighted averaged on Test Set for KNN Classifier: 0.7082888419437557\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score on Test Set for KNN Classifier: {}\".format(accuracy_score(y_test, y_pred_knn)))\n",
    "print(\"Precision Score - weighted averaged on Test Set for KNN Classifier: {}\".format(precision_score(y_test, y_pred_knn, average='weighted')))\n",
    "print(\"ROC-AUC score - weighted averaged on Test Set for KNN Classifier: {}\".format(roc_auc_score(y_test, y_probs_knn, average='weighted', multi_class='ovo')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In both cases, the Random Forest Classifier outperforms the KNN Classifier. \n",
    "\n",
    "For the RF Classifier we can use the hyperparameters found through RandomizedSearchCV: {'n_estimators': 200, 'max_features': 'auto', 'criterion': 'gini'}.\n",
    "\n",
    "Surprisingly the accuracy on the test set is quite good, even a tiny bit higher than the train set at 0.85."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
